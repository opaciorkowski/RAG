{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c71f0917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from advanced_rag import *\n",
    "import json\n",
    "from ragas import EvaluationDataset, evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745b23aa",
   "metadata": {},
   "source": [
    "## Creating necessery variables such as vectore base and declaring a llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c780a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new documents to add.\n"
     ]
    }
   ],
   "source": [
    "db, llm = initialize_rag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd839fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm.model_name: gpt-3.5-turbo\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"llm.model_name:\", llm.model_name)\n",
    "except AttributeError:\n",
    "    print(\"llm.model:\", llm.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674c29a4",
   "metadata": {},
   "source": [
    "## Create Evaluation Dataset\n",
    "\n",
    "We are building a dataset for RAGAS evaluation using questions and ground truth answers from `qa_eval.json`.\n",
    "\n",
    "For each entry, we will include:\n",
    "- **user_input**: the question\n",
    "- **response**: the answer generated by the LLM using retrieved context\n",
    "- **retrieved_contexts**: the documents returned by the retriever\n",
    "- **reference**: the ground truth answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "382ab76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eval_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        eval_data = json.load(file)\n",
    "        queries = [entry[\"question\"] for entry in eval_data]\n",
    "        ground_truth = [entry[\"ground_truth\"] for entry in eval_data]\n",
    "    return queries, ground_truth\n",
    "\n",
    "def create_evaluation_dataset(answers, contexts, queries, ground_truth):\n",
    "    eval_dataset = []\n",
    "    for i in range(len(queries)):\n",
    "        eval_dataset.append({\n",
    "            \"user_input\": queries[i],\n",
    "            \"response\": answers[i],\n",
    "            \"retrieved_contexts\": contexts[i],\n",
    "            \"reference\": ground_truth[i]\n",
    "        })\n",
    "    return eval_dataset\n",
    "\n",
    "def extract_and_print_contexts(result):\n",
    "    contexts = [doc.page_content for doc in result.get(\"source_documents\", [])]\n",
    "    return contexts\n",
    "\n",
    "def run_queries(rag_chain, file_path):\n",
    "    results = []\n",
    "    contexts = []\n",
    "    queries, ground_truth = load_eval_data(file_path)\n",
    "    for query in queries:\n",
    "        result = rag_chain({\"question\": query, \"chat_history\": []})\n",
    "        results.append(result['answer'])\n",
    "        contexts.append(extract_and_print_contexts(result))\n",
    "    return create_evaluation_dataset(results, contexts, queries, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d1afa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dataset(evaluation_dataset, llm):\n",
    "    evaluator_llm = LangchainLLMWrapper(llm)\n",
    "    print(type(evaluator_llm))\n",
    "    print(evaluator_llm)\n",
    "    result = evaluate(\n",
    "        dataset=evaluation_dataset,\n",
    "        metrics=[\n",
    "            LLMContextRecall(), \n",
    "            Faithfulness(), \n",
    "            FactualCorrectness()\n",
    "        ],\n",
    "        llm=evaluator_llm,\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8d0375f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dataset_to_df(dataset):\n",
    "    return pd.DataFrame([\n",
    "        {\n",
    "            \"Question\": entry[\"user_input\"],\n",
    "            \"Response\": entry[\"response\"],\n",
    "            \"Context (1st)\": entry[\"retrieved_contexts\"][0] if entry[\"retrieved_contexts\"] else \"\",\n",
    "            \"Ground Truth\": entry[\"reference\"],\n",
    "        }\n",
    "        for entry in dataset\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e0b78cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_result_to_df(results) -> pd.DataFrame:\n",
    "    scores_dict = results._scores_dict\n",
    "    df = pd.DataFrame(scores_dict).T\n",
    "    df.columns = [f\"q{i+1}\" for i in range(df.shape[1])]\n",
    "    df[\"avg\"] = df.mean(axis=1).round(4)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69c38fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain, rag_memory = create_rag_chain(\n",
    "    vectorstore=db,\n",
    "    llm=llm,\n",
    "    prompt_type='react',\n",
    "    use_memory=True,\n",
    "    retriever_k=3,\n",
    "    use_reranking=False,\n",
    "    top_k_chunks=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9bd8607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm.model_name: gpt-3.5-turbo\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"llm.model_name:\", llm.model_name)\n",
    "except AttributeError:\n",
    "    print(\"llm.model:\", llm.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86904b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'ragas.llms.base.LangchainLLMWrapper'>\n",
      "LangchainLLMWrapper(langchain_llm=ChatOpenAI(...))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "191bca9b718a4a75a71bfa95135063d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_recall': 1.0000, 'faithfulness': 0.8333, 'factual_correctness(mode=f1)': 0.4533}\n"
     ]
    }
   ],
   "source": [
    "file_path = 'qa_eval.json'\n",
    "dataset = run_queries(rag_chain, file_path)\n",
    "eval_dataset = EvaluationDataset.from_list(dataset)\n",
    "results = evaluate_dataset(eval_dataset, llm)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01132154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "      <th>q3</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>context_recall</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faithfulness</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>factual_correctness(mode=f1)</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                q1    q2   q3     avg\n",
       "context_recall                1.00  1.00  1.0  1.0000\n",
       "faithfulness                  1.00  0.50  1.0  0.8333\n",
       "factual_correctness(mode=f1)  0.67  0.29  0.4  0.4533"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = evaluation_result_to_df(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "83c41f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Response</th>\n",
       "      <th>Context (1st)</th>\n",
       "      <th>Ground Truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is a Pokémon EX card?</td>\n",
       "      <td>Question: What is a Pokémon EX card?\\nThought:...</td>\n",
       "      <td>28\\nPokémon T rading Card Game Rules\\nAPPENDIX...</td>\n",
       "      <td>Pokémon-EX cards are a special kind of card th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What does haste do in Magic: The Gathering?</td>\n",
       "      <td>Question: What does haste do in Magic: The Gat...</td>\n",
       "      <td>702.8b Multiple instances of flash on the same...</td>\n",
       "      <td>Haste is a keyword that allows a creature to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can a player build a hotel in Monopoly?</td>\n",
       "      <td>Question: How can a player build a hotel in Mo...</td>\n",
       "      <td>HOTELS...When a player has four houses on each...</td>\n",
       "      <td>A player must have four houses on every proper...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Question  \\\n",
       "0                   What is a Pokémon EX card?   \n",
       "1  What does haste do in Magic: The Gathering?   \n",
       "2  How can a player build a hotel in Monopoly?   \n",
       "\n",
       "                                            Response  \\\n",
       "0  Question: What is a Pokémon EX card?\\nThought:...   \n",
       "1  Question: What does haste do in Magic: The Gat...   \n",
       "2  Question: How can a player build a hotel in Mo...   \n",
       "\n",
       "                                       Context (1st)  \\\n",
       "0  28\\nPokémon T rading Card Game Rules\\nAPPENDIX...   \n",
       "1  702.8b Multiple instances of flash on the same...   \n",
       "2  HOTELS...When a player has four houses on each...   \n",
       "\n",
       "                                        Ground Truth  \n",
       "0  Pokémon-EX cards are a special kind of card th...  \n",
       "1  Haste is a keyword that allows a creature to a...  \n",
       "2  A player must have four houses on every proper...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = eval_dataset_to_df(dataset)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
