{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RAG System with Gemini and FAISS\n",
        "# ================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "from typing import List\n",
        "from dotenv import load_dotenv\n",
        "import requests\n",
        "from langchain.schema import Document\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "from langchain.chains import RetrievalQA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration\n",
        "First, let's set up the configuration for our RAG system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Configuration settings\n",
        "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
        "CHUNK_SIZE = 800\n",
        "CHUNK_OVERLAP = 80\n",
        "RETRIEVER_K = 4\n",
        "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
        "\n",
        "if not GEMINI_API_KEY:\n",
        "    raise ValueError(\"GEMINI_API_KEY not found in environment variables\")\n",
        "\n",
        "# Initialize LLM\n",
        "llm = GoogleGenerativeAI(\n",
        "    api_key=GEMINI_API_KEY,\n",
        "    model=\"gemini-2.0-flash\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Document Processing Functions\n",
        "Let's define functions to download and process PDF documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def download_pdf(url: str, folder: str = 'documents') -> str:\n",
        "    \"\"\"\n",
        "    Downloads PDF from given URL\n",
        "    \n",
        "    Args:\n",
        "        url (str): URL to download from\n",
        "        folder (str): Destination folder\n",
        "        \n",
        "    Returns:\n",
        "        str: Path to downloaded file\n",
        "    \"\"\"\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    filename = os.path.basename(url)\n",
        "    filepath = os.path.join(folder, filename)\n",
        "    \n",
        "    response = requests.get(url, timeout=10)\n",
        "    response.raise_for_status()\n",
        "    \n",
        "    with open(filepath, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "    return filepath\n",
        "\n",
        "def process_document(url: str, chunk_size: int, chunk_overlap: int) -> List[Document]:\n",
        "    \"\"\"\n",
        "    Process document from URL to chunks\n",
        "    \n",
        "    Args:\n",
        "        url (str): Document URL\n",
        "        chunk_size (int): Size of each text chunk\n",
        "        chunk_overlap (int): Overlap between chunks\n",
        "        \n",
        "    Returns:\n",
        "        List[Document]: List of document chunks\n",
        "    \"\"\"\n",
        "    filepath = download_pdf(url)\n",
        "    loader = PyPDFLoader(filepath)\n",
        "    pages = loader.load()\n",
        "    \n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap\n",
        "    )\n",
        "    chunks = splitter.split_documents(pages)\n",
        "    \n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Vector Store Creation\n",
        "Now let's create a function to build our vector store from documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_vectorstore(documents: List[Document], embedding_model: str) -> FAISS:\n",
        "    \"\"\"\n",
        "    Create and save a FAISS vector store from documents\n",
        "    \n",
        "    Args:\n",
        "        documents (List[Document]): List of document chunks\n",
        "        embedding_model (str): Name of the embedding model\n",
        "        \n",
        "    Returns:\n",
        "        FAISS: Vector store for document retrieval\n",
        "    \"\"\"\n",
        "    embeddings = OpenAIEmbeddings(model=embedding_model)\n",
        "    \n",
        "    vectorstore = FAISS.from_documents(\n",
        "        documents=documents,\n",
        "        embedding=embeddings\n",
        "    )\n",
        "    \n",
        "    # Save vector store for later use\n",
        "    vectorstore.save_local(\"faiss_index\")\n",
        "    \n",
        "    return vectorstore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. RAG Chain Creation\n",
        "Let's create our RAG chain with the Gemini model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_rag_chain(vectorstore: FAISS, llm, retriever_k: int = 4) -> ConversationalRetrievalChain:\n",
        "    \"\"\"\n",
        "    Create a conversational retrieval chain\n",
        "    \n",
        "    Args:\n",
        "        vectorstore (FAISS): Vector store for retrieval\n",
        "        llm: Language model\n",
        "        retriever_k (int): Number of documents to retrieve\n",
        "        \n",
        "    Returns:\n",
        "        ConversationalRetrievalChain: RAG chain\n",
        "    \"\"\"\n",
        "    template = \"\"\"Use the following pieces of context to answer the question. Explain like you are talking to a 5-year-old. If the question is not related to the context, say \"I don't know\".\n",
        "    If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "\n",
        "    Context: {context}\n",
        "\n",
        "    Question: {question}\n",
        "\n",
        "    Provide a clear and concise answer. If possible, cite specific parts from the context.\n",
        "\n",
        "    Answer:\"\"\"\n",
        "\n",
        "    prompt = PromptTemplate(\n",
        "        template=template,\n",
        "        input_variables=[\"context\", \"question\"]\n",
        "    )\n",
        "\n",
        "    # Create the chain\n",
        "    chain = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=vectorstore.as_retriever(\n",
        "            search_type=\"similarity\",\n",
        "            search_kwargs={\"k\": retriever_k}\n",
        "        ),\n",
        "        chain_type_kwargs={\"prompt\": prompt},\n",
        "        return_source_documents=True\n",
        "    )\n",
        "    return chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Building the Complete RAG System\n",
        "Now let's put everything together to build our RAG system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_rag_system(document_url: str):\n",
        "    \"\"\"\n",
        "    Build the complete RAG system from a document URL\n",
        "    \n",
        "    Args:\n",
        "        document_url (str): URL of the document\n",
        "        \n",
        "    Returns:\n",
        "        ConversationalRetrievalChain: Ready-to-use RAG chain\n",
        "    \"\"\"\n",
        "    # Process document\n",
        "    chunks = process_document(document_url, CHUNK_SIZE, CHUNK_OVERLAP)\n",
        "    print(f\"Document processed into {len(chunks)} chunks\")\n",
        "    \n",
        "    # Create vector store\n",
        "    vectorstore = create_vectorstore(chunks, EMBEDDING_MODEL)\n",
        "    print(\"Vector store created successfully\")\n",
        "    \n",
        "    # Create RAG chain\n",
        "    chain = create_rag_chain(vectorstore, llm, RETRIEVER_K)\n",
        "    print(\"RAG chain created successfully\")\n",
        "    \n",
        "    return chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Running the System\n",
        "Let's run the system on a sample document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document processed into 925 chunks\n",
            "Vector store created successfully\n",
            "RAG chain created successfully\n"
          ]
        }
      ],
      "source": [
        "# Build the RAG system\n",
        "document_url = 'https://media.wizards.com/images/magic/tcg/resources/rules/MagicCompRules_21031101.pdf'\n",
        "rag_chain = build_rag_system(document_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Testing with Sample Queries\n",
        "Let's test our RAG system with some sample queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def query_rag(chain, question: str):\n",
        "    \"\"\"\n",
        "    Query the RAG system and display results\n",
        "    \n",
        "    Args:\n",
        "        chain: RAG chain\n",
        "        question (str): Question to ask\n",
        "    \"\"\"\n",
        "    result = chain({\"question\": question})\n",
        "    \n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Query: {question}\")\n",
        "    print(f\"Answer: {result['answer']}\")\n",
        "    print(\"\\nSources:\")\n",
        "    for i, doc in enumerate(result['source_documents'][:2], 1):\n",
        "        print(f\"\\nSource {i}:\")\n",
        "        print(f\"Content: {doc.page_content[:150]}...\")\n",
        "    print(f\"{'='*50}\\n\")\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\oskar\\AppData\\Local\\Temp\\ipykernel_10096\\1081698975.py:9: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = chain({\"question\": question})\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Missing some input keys: {'chat_history'}",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 11\u001b[0m\n\u001b[0;32m      2\u001b[0m test_queries \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the purpose of the rules in the document?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan you explain the concept of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in simple terms?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the role of the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in gameplay?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m ]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m test_queries:\n\u001b[1;32m---> 11\u001b[0m     \u001b[43mquery_rag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrag_chain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[8], line 9\u001b[0m, in \u001b[0;36mquery_rag\u001b[1;34m(chain, question)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery_rag\u001b[39m(chain, question: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    Query the RAG system and display results\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m        question (str): Question to ask\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\oskar\\PycharmProjects\\pythonProject\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:181\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     emit_warning()\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\oskar\\PycharmProjects\\pythonProject\\venv\\lib\\site-packages\\langchain\\chains\\base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    387\u001b[0m }\n\u001b[1;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\oskar\\PycharmProjects\\pythonProject\\venv\\lib\\site-packages\\langchain\\chains\\base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
            "File \u001b[1;32mc:\\Users\\oskar\\PycharmProjects\\pythonProject\\venv\\lib\\site-packages\\langchain\\chains\\base.py:158\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    153\u001b[0m     inputs,\n\u001b[0;32m    154\u001b[0m     run_id,\n\u001b[0;32m    155\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m    156\u001b[0m )\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    167\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\oskar\\PycharmProjects\\pythonProject\\venv\\lib\\site-packages\\langchain\\chains\\base.py:290\u001b[0m, in \u001b[0;36mChain._validate_inputs\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    288\u001b[0m missing_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_keys)\u001b[38;5;241m.\u001b[39mdifference(inputs)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_keys:\n\u001b[1;32m--> 290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing some input keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mValueError\u001b[0m: Missing some input keys: {'chat_history'}"
          ]
        }
      ],
      "source": [
        "# Test some queries\n",
        "test_queries = [\n",
        "    \"What is the purpose of the rules in the document?\",\n",
        "    \"Can you explain the concept of 'combat' in simple terms?\",\n",
        "    \"What are the main sections of the document?\",\n",
        "    \"How does one win a game of Magic: The Gathering?\",\n",
        "    \"What is the role of the 'stack' in gameplay?\"\n",
        "]\n",
        "\n",
        "for query in test_queries:\n",
        "    query_rag(rag_chain, query)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
